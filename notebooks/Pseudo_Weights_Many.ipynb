{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # This allows for importing from other directories above\n",
    "# Our imports\n",
    "from models.adaboost_mh import AdaBoostMH\n",
    "from models.weak_learner import stump_base as weak_clf\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load('../data/synth/single/three/train_data.npy')\n",
    "y_train = np.load('../data/synth/single/three/train_labels.npy')\n",
    "X_test = np.load('../data/synth/single/three/test_data.npy')\n",
    "y_test = np.load('../data/synth/single/three/test_labels.npy')\n",
    "k = 3\n",
    "  \n",
    "y_train = y_train[0:15]\n",
    "X_train = X_train[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50000\n",
    "verbose = 0\n",
    "num_rounds = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pseudo_ws(Wts, vts, Y, T):\n",
    "    w_pseudo_ts = []\n",
    "    for t in range(T):\n",
    "        W_t = Wts[t]\n",
    "        v_t = vts[t]\n",
    "        # Get all the y_i,l * v_l in one matrix\n",
    "        Y_mult_v_t = np.multiply(Y, v_t)\n",
    "        # The above is either 1 or -1, to get an indicator\n",
    "        # about whether their product is +1 or -1 you can \n",
    "        # add one to the whole matrix and all the -1 -> 0,\n",
    "        # or add negative one to the whole matrix and all\n",
    "        # the +1 -> 0. You just need to normalize by \\pm 1/2,\n",
    "        # to get an indicator or a matrix mask.\n",
    "        w_p_mask = ((Y_mult_v_t + 1) * 0.5).astype('int')\n",
    "        w_n_mask = ((Y_mult_v_t - 1) * -0.5).astype('int')\n",
    "        w_p_t = np.sum(np.multiply(W_t, w_p_mask), axis=1)\n",
    "        w_n_t = np.sum(np.multiply(W_t, w_n_mask), axis=1)\n",
    "        w_pseudo_t = np.sum(np.abs(w_p_t - w_n_t))\n",
    "        w_pseudo_ts.append(w_pseudo_t)\n",
    "    return w_pseudo_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb99b660ea0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostMH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_factorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpseudo_W_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_pseudo_ws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpseudo_W_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/COS-511-Project/models/adaboost_mh.py\u001b[0m in \u001b[0;36mrun_factorized\u001b[0;34m(self, T, weak_learner, W_init, verbose)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Get error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_ts_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mH_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_ts_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Calculate the error of H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mins = []\n",
    "num_data_points = []\n",
    "for i in range(num_rounds):\n",
    "    print(i)\n",
    "    model = AdaBoostMH(X_train, y_train, X_test, y_test, 0.8)\n",
    "    _, _, _, v_ts, d_ts = model.run_factorized(T, weak_clf, 'unif', verbose)\n",
    "    pseudo_W_ts = calc_pseudo_ws(d_ts, v_ts, y_train, T)\n",
    "    mins.append(np.min(pseudo_W_ts))\n",
    "    \n",
    "    y_train = np.concatenate((y_train, y_train), axis=0)\n",
    "    n = y_train.shape[0]\n",
    "    num_data_points.append(n)\n",
    "    X_train = np.atleast_2d(np.array(list(range(0,n)))).T\n",
    "    #print(X_train)\n",
    "    #print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Pseudo Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting Pseudo weights on same plot for two datasets\n",
    "def make_plot(mins, num_data_points, ylabel, xlabel, title):\n",
    "    plt.scatter(num_data_points, mins) #, label='Pseudo Weights')\n",
    "    #plt.legend(loc='best')\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "    plt.xlabel(xlabel, fontsize=22)\n",
    "    plt.ylabel(ylabel, fontsize=22)\n",
    "    plt.title(title, fontsize=22)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,0.12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c14d7670bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\"Minimum $w'_\\Sigma$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of Training Examples\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\"Minimum $w'_\\Sigma$ on Synthetic Dataset Family\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_plot' is not defined"
     ]
    }
   ],
   "source": [
    "make_plot(mins, num_data_points, r\"Minimum $w'_\\Sigma$\", \"Number of Training Examples\", r\"Minimum $w'_\\Sigma$ on Synthetic Dataset Family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1122836591050339,\n",
       " 0.05947666872573679,\n",
       " 0.03381190005650993,\n",
       " 0.017730764170532716,\n",
       " 0.009173226745153461,\n",
       " 0.004218067858288857,\n",
       " 0.0028254712793095867,\n",
       " 0.33333333333333326]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
