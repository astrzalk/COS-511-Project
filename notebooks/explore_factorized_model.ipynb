{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # This allows for importing from other directories above\n",
    "# Our imports\n",
    "from models.adaboost_mh import AdaBoostMH\n",
    "from models.weak_learner import stump_base as weak_clf\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load('../data/pendigits/pendigits_train_data.npy')\n",
    "y_train = np.load('../data/pendigits/pendigits_train_labels.npy')\n",
    "X_test = np.load('../data/pendigits/pendigits_test_data.npy')\n",
    "y_test = np.load('../data/pendigits/pendigits_test_labels.npy')\n",
    "\n",
    "# Initialize model \n",
    "model = AdaBoostMH(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "T, W_init = 19, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d3ecf8111bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test that it runs okay just for a single T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0merr_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_factorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# verbose True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The training error is {}.\\nThe testing error is {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COS 511/Project/code/models/adaboost_mh.py\u001b[0m in \u001b[0;36mrun_factorized\u001b[0;34m(self, T, weak_learner, W_init, verbose)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Round {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;31m# Fit weak learner to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0malpha_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mvts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Make v a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "# Test that it runs okay just for a single T\n",
    "err_tr, err_te, gammas, D_ts = model.run_factorized(T, weak_clf, W_init) # verbose True\n",
    "print(\"The training error is {}.\\nThe testing error is {}.\".format(err_tr, err_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model. Note this should be the longest step.\n",
    "model_performance = [model.run_factorized(T, weak_clf, W_init) for t in range(T)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model performance metrics into separate lists\n",
    "model_tuples = [[tups[i] for tups in model_performance] for i in range(4)] # 4 = num ele in each tuple \n",
    "err_tr, err_te, gammas, D_ts = model_tuples[0], model_tuples[1], model_tuples[2], model_tuples[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting training and testing error on same plot\n",
    "def plot_error(err_tr, err_te, title):\n",
    "    T = len(err_tr)\n",
    "    ts = np.linspace(1, T, num=T)\n",
    "    plt.plot(ts, err_tr, label='Training Error')\n",
    "    plt.plot(ts, err_te, label='Testing Error')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"T\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecdf taken from https://stackoverflow.com/questions/15792552/numpy-scipy-equivalent-of-r-ecdfxx-function\n",
    "# ecdf = Empirical Cumulative Distribution Function\n",
    "def ecdf(x):\n",
    "    xs = np.sort(x)\n",
    "    ys = np.arange(1, len(xs)+1)/float(len(xs))\n",
    "    return xs, ys\n",
    "\n",
    "# Function for plotting the gammas, either plots ecdf or gamma change over rounds\n",
    "def plot_gammas(gammas, which_plot, title):\n",
    "    if which_plot == 'cdf':\n",
    "        xs, ys = ecdf(gammas)\n",
    "        plt.plot(xs, ys)\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        T = len(gammas)\n",
    "        ts = np.linspace(1, T, num=T)\n",
    "        plt.plot(ts, gammas)\n",
    "        plt.xlabel(\"T\")\n",
    "        plt.ylabel(\"gamma\")\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing error\n",
    "title = \"Error for Factorized Model on Penn Digits\"\n",
    "plot_error(err_tr, err_te, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot change for gamma_t over T rounds\n",
    "plot_gammas(gammas, 'gamma_rate', 'Gamma over T rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cdf for gammas\n",
    "plot_gammas(gammas, 'cdf', 'CDF for Gammas over all rounds T')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
